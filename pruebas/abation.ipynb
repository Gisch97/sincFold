{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch as tr\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import torch.nn as nn\n",
    "from sincfold.dataset import SeqDataset, pad_batch\n",
    "from torch.utils.data import DataLoader\n",
    "from sincfold.model import sincfold, SincFold\n",
    "from sincfold.embeddings import NT_DICT\n",
    "from sincfold.utils import write_ct, validate_file, ct2dot\n",
    "from sincfold.parser import parser\n",
    "from sincfold.utils import dot2png, ct2svg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser e hiperparametros, semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# args = parser()\n",
    "\n",
    "# if not args.no_cache and args.command == \"train\":\n",
    "#     cache_path = \"cache/\"\n",
    "# else:\n",
    "#     cache_path = None\n",
    "\n",
    "# config= {\"device\": args.d, \"batch_size\": args.batch, \n",
    "#             \"valid_split\": 0.1, \"max_len\": args.max_length, \"verbose\": not args.quiet, \"cache_path\": cache_path}\n",
    "\n",
    "# if \"max_epochs\" in args:\n",
    "#     config[\"max_epochs\"] = args.max_epochs\n",
    "\n",
    "# if args.config is not None:\n",
    "#     config.update(json.load(open(args.config)))\n",
    "\n",
    "# if config[\"cache_path\"] is not None:\n",
    "#     shutil.rmtree(config[\"cache_path\"], ignore_errors=True)\n",
    "#     os.makedirs(config[\"cache_path\"])\n",
    "\n",
    "# # Reproducibility\n",
    "# tr.manual_seed(42)\n",
    "# random.seed(42)\n",
    "# np.random.seed(42)\n",
    "\n",
    "# if args.command == \"train\": \n",
    "#     train(args.train_file, config, args.out_path,  args.valid_file, args.j)\n",
    "\n",
    "# if args.command == \"test\":\n",
    "#     test(args.test_file, args.model_weights, args.out_path, config, args.j)\n",
    "\n",
    "# if args.command == \"pred\":\n",
    "#     pred(args.pred_file, model_weights=args.model_weights, out_path=args.out_path, logits=args.logits, config=config, nworkers=args.j, draw=args.draw, draw_resolution=args.draw_resolution)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reproducibility\n",
    "tr.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Params\n",
    "train_file ='../data/ArchiveII_sample.csv'\n",
    "config={}\n",
    "out_path=None\n",
    "valid_file=None\n",
    "nworkers=2\n",
    "verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on results_2024-10-07-13:14:06.448821/\n",
      "No weights provided, using random initialization\n",
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:56<00:00, 198.88s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch,train_f1,train_loss,valid_f1,valid_f1_post,valid_loss\n",
      "\n",
      "0,0.0016,0.5476,0.0000,0.0000,0.1929\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:09<00:00, 183.16s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,0.0000,0.2032,0.0000,0.0000,0.2465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:46<00:00, 195.39s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,0.0000,0.2356,0.0000,0.0000,0.2406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [11:30<00:00, 230.26s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,0.0000,0.1556,0.0000,0.0000,0.2045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:41<00:00, 193.80s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,0.0000,0.1079,0.0000,0.0000,0.1705\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:59<00:00, 159.94s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,0.0000,0.0802,0.0000,0.0000,0.1437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [05:26<00:00, 108.69s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,0.0160,0.0896,0.1143,0.1143,0.1232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:54<00:00, 98.30s/it] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,0.1481,0.0546,0.3043,0.3256,0.1092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:54<00:00, 98.24s/it] \n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,0.1523,0.0535,0.3396,0.3265,0.0962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [05:05<00:00, 101.79s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9,0.2534,0.0710,0.3396,0.3333,0.0880\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:22<00:00, 167.37s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,0.2304,0.0446,0.4561,0.4615,0.0848\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:09<00:00, 143.06s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,0.1942,0.0462,0.4407,0.4444,0.0833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:18<00:00, 186.04s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,0.2192,0.0399,0.4444,0.4643,0.0815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:40<00:00, 173.57s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,0.2862,0.0528,0.4348,0.4590,0.0804\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:33<00:00, 171.32s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,0.2154,0.0416,0.4478,0.4667,0.0813\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:15<00:00, 165.30s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15,0.2573,0.0429,0.4839,0.4912,0.0848\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:56<00:00, 158.87s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,0.2406,0.0556,0.4483,0.4528,0.0887\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:47<00:00, 155.87s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17,0.2612,0.0531,0.4333,0.4364,0.0866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:31<00:00, 190.34s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,0.2836,0.0400,0.4839,0.4912,0.0829\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:13<00:00, 184.50s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19,0.2874,0.0529,0.4839,0.4912,0.0819\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:00<00:00, 160.29s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20,0.2663,0.0367,0.4407,0.4444,0.0859\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:57<00:00, 179.27s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,0.2699,0.0363,0.4286,0.4314,0.0939\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:33<00:00, 171.06s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22,0.3197,0.0361,0.4286,0.4314,0.0928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [06:34<00:00, 131.46s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23,0.3315,0.0468,0.4483,0.4528,0.0831\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:59<00:00, 159.83s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24,0.3436,0.0411,0.4839,0.4912,0.0774\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:18<00:00, 166.32s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25,0.4056,0.0397,0.4918,0.5000,0.0772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:19<00:00, 166.53s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26,0.3655,0.0413,0.5000,0.5091,0.0795\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [06:35<00:00, 131.80s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27,0.3788,0.0429,0.4828,0.4615,0.0806\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:25<00:00, 168.52s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28,0.3213,0.0318,0.4561,0.4314,0.0814\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:10<00:00, 163.41s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29,0.3396,0.0304,0.4643,0.4400,0.0800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:25<00:00, 148.44s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30,0.4100,0.0347,0.4828,0.4615,0.0771\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:19<00:00, 146.63s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31,0.4402,0.0332,0.5246,0.5091,0.0733\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:03<00:00, 161.28s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32,0.4425,0.0344,0.5000,0.4815,0.0741\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [06:09<00:00, 123.13s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33,0.4936,0.0359,0.4912,0.4615,0.0777\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:30<00:00, 150.33s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34,0.4634,0.0348,0.4828,0.4615,0.0759\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:50<00:00, 176.70s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35,0.4841,0.0284,0.4918,0.4727,0.0735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:49<00:00, 156.51s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36,0.4298,0.0300,0.4727,0.4314,0.0823\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:48<00:00, 156.12s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,0.5123,0.0301,0.4727,0.4314,0.0823\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:36<00:00, 172.13s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38,0.5727,0.0278,0.5000,0.4727,0.0738\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:49<00:00, 176.41s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39,0.3874,0.0270,0.5085,0.4815,0.0747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:29<00:00, 149.86s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40,0.5303,0.0290,0.4727,0.4314,0.0771\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:34<00:00, 151.38s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41,0.4860,0.0266,0.4912,0.4528,0.0724\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:35<00:00, 151.80s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42,0.6201,0.0246,0.5397,0.4912,0.0684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:14<00:00, 164.67s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43,0.5322,0.0243,0.5667,0.5091,0.0708\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:41<00:00, 173.67s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44,0.4854,0.0226,0.4906,0.4400,0.0770\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:45<00:00, 175.12s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45,0.4866,0.0241,0.5000,0.4898,0.0827\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:34<00:00, 171.55s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46,0.6128,0.0236,0.5763,0.5455,0.0710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:55<00:00, 158.54s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47,0.6578,0.0208,0.5484,0.5357,0.0665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:44<00:00, 174.68s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48,0.5943,0.0234,0.4815,0.4706,0.0760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:07<00:00, 182.63s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49,0.6044,0.0211,0.4800,0.5106,0.0853\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:45<00:00, 175.27s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50,0.5791,0.0204,0.5862,0.5818,0.0688\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:33<00:00, 191.18s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51,0.4923,0.0199,0.4800,0.5106,0.0948\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [05:47<00:00, 115.84s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52,0.6004,0.0212,0.4167,0.4444,0.1019\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:12<00:00, 184.21s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53,0.5664,0.0203,0.5862,0.6182,0.0701\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:24<00:00, 148.08s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54,0.5035,0.0192,0.5574,0.6071,0.0646\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:22<00:00, 187.45s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55,0.5403,0.0174,0.4800,0.5106,0.0794\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:01<00:00, 180.63s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56,0.6898,0.0181,0.4800,0.5106,0.0802\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:41<00:00, 173.71s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57,0.7128,0.0176,0.5862,0.6182,0.0707\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [04:14<08:29, 254.57s/it]"
     ]
    }
   ],
   "source": [
    "if out_path is None:\n",
    "    out_path = f\"results_{str(datetime.today()).replace(' ', '-')}/\"\n",
    "else:\n",
    "    out_path = out_path\n",
    "\n",
    "if verbose:\n",
    "    print(\"Working on\", out_path)\n",
    "\n",
    "if \"cache_path\" not in config:\n",
    "    config[\"cache_path\"] = \"cache/\"\n",
    "\n",
    "if not os.path.isdir(out_path):\n",
    "    os.makedirs(out_path)\n",
    "else:\n",
    "    raise ValueError(f\"Output path {out_path} already exists\")\n",
    "\n",
    "if valid_file is not None:\n",
    "    train_file = train_file\n",
    "    valid_file = valid_file\n",
    "else:\n",
    "    data = pd.read_csv(train_file)\n",
    "    valid_split = config[\"valid_split\"] if \"valid_split\" in config else 0.1\n",
    "    train_file = os.path.join(out_path, \"train.csv\")\n",
    "    valid_file = os.path.join(out_path, \"valid.csv\")\n",
    "\n",
    "    val_data = data.sample(frac = valid_split)\n",
    "    val_data.to_csv(valid_file, index=False)\n",
    "    data.drop(val_data.index).to_csv(train_file, index=False)\n",
    "    \n",
    "batch_size = config[\"batch_size\"] if \"batch_size\" in config else 4\n",
    "train_loader = DataLoader(\n",
    "    SeqDataset(train_file, training=True, **config),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=nworkers,\n",
    "    collate_fn=pad_batch\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    SeqDataset(valid_file, **config),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=nworkers,\n",
    "    collate_fn=pad_batch,\n",
    ")\n",
    "\n",
    "net = sincfold(train_len=len(train_loader), **config)\n",
    "\n",
    "best_f1, patience_counter = -1, 0\n",
    "patience = config[\"patience\"] if \"patience\" in config else 30\n",
    "if verbose:\n",
    "    print(\"Start training...\")\n",
    "max_epochs = config[\"max_epochs\"] if \"max_epochs\" in config else 1000\n",
    "logfile = os.path.join(out_path, \"train_log.csv\") \n",
    "    \n",
    "for epoch in range(max_epochs):\n",
    "    train_metrics = net.fit(train_loader)\n",
    "\n",
    "    val_metrics = net.test(valid_loader)\n",
    "\n",
    "    if val_metrics[\"f1\"] > best_f1:\n",
    "        best_f1 = val_metrics[\"f1\"]\n",
    "        tr.save(net.state_dict(), os.path.join(out_path, \"weights.pmt\"))\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter > patience:\n",
    "            break\n",
    "    \n",
    "    if not os.path.exists(logfile):\n",
    "        with open(logfile, \"w\") as f: \n",
    "            msg = ','.join(['epoch']+[f\"train_{k}\" for k in sorted(train_metrics.keys())]+[f\"valid_{k}\" for k in sorted(val_metrics.keys())]) + \"\\n\"\n",
    "            f.write(msg)\n",
    "            f.flush()\n",
    "            if verbose:\n",
    "                print(msg)\n",
    "\n",
    "    with open(logfile, \"a\") as f: \n",
    "        msg = ','.join([str(epoch)]+[f'{train_metrics[k]:.4f}' for k in sorted(train_metrics.keys())]+[f'{val_metrics[k]:.4f}' for k in sorted(val_metrics.keys())]) + \"\\n\"\n",
    "        f.write(msg)\n",
    "        f.flush()    \n",
    "        if verbose:\n",
    "            print(msg)\n",
    "        \n",
    "# remove temporal files           \n",
    "shutil.rmtree(config[\"cache_path\"], ignore_errors=True)\n",
    "\n",
    "tmp_file = os.path.join(out_path, \"train.csv\")\n",
    "if os.path.exists(tmp_file):\n",
    "    os.remove(tmp_file)\n",
    "tmp_file = os.path.join(out_path, \"valid.csv\")\n",
    "if os.path.exists(tmp_file):\n",
    "    os.remove(tmp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Parameters: FIXED\n",
    "test_file = '../data/ArchiveII_sample.csv'\n",
    "model_weights=None\n",
    "output_file=None\n",
    "config={}\n",
    "nworkers=2\n",
    "verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained weights...\n"
     ]
    }
   ],
   "source": [
    "# LOAD the test dataset\n",
    "test_file = test_file\n",
    "test_file = validate_file(test_file)\n",
    "if verbose not in config:\n",
    "    config[\"verbose\"] = verbose\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    SeqDataset(test_file, **config),\n",
    "    batch_size=config[\"batch_size\"] if \"batch_size\" in config else 4,\n",
    "    shuffle=False,\n",
    "    num_workers=nworkers,\n",
    "    collate_fn=pad_batch,\n",
    ")\n",
    "\n",
    "if model_weights is not None:\n",
    "    net = sincfold(weights=model_weights, **config)\n",
    "else:\n",
    "    net = sincfold(pretrained=True, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SincFold(\n",
       "  (resnet1d): Sequential(\n",
       "    (0): Conv1d(4, 32, kernel_size=(3,), stride=(1,), padding=same)\n",
       "    (1): ResidualLayer1D(\n",
       "      (layer): Sequential(\n",
       "        (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=same, dilation=(3,))\n",
       "        (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Conv1d(16, 32, kernel_size=(1,), stride=(1,), padding=same)\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualLayer1D(\n",
       "      (layer): Sequential(\n",
       "        (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=same, dilation=(3,))\n",
       "        (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Conv1d(16, 32, kernel_size=(1,), stride=(1,), padding=same)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (convrank1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (convrank2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (resnet2d): Sequential(\n",
       "    (0): Conv2d(2, 256, kernel_size=(7, 7), stride=(1, 1), padding=same)\n",
       "    (1): ResidualBlock2D(\n",
       "      (layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, dilation=(3, 3))\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock2D(\n",
       "      (layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, dilation=(3, 3))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv2Dout): Conv2d(256, 1, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test of ../data/ArchiveII_sample.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:19<00:00, 46.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1,f1_post,loss\n",
      "0.944,0.950,0.005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    print(f\"Start test of {test_file}\")        \n",
    "test_metrics = net.test(test_loader)\n",
    "summary = \",\".join([k for k in sorted(test_metrics.keys())]) + \"\\n\" + \",\".join([f\"{test_metrics[k]:.3f}\" for k in sorted(test_metrics.keys())])+ \"\\n\" \n",
    "if output_file is not None:\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(summary)\n",
    "if verbose:\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear y probar la calse AblationNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino las clases de las capas residuales\n",
    "class ResidualLayer1D(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dilation,\n",
    "        resnet_bottleneck_factor,\n",
    "        filters,\n",
    "        kernel_size,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        num_bottleneck_units = math.floor(resnet_bottleneck_factor * filters)\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.BatchNorm1d(filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(\n",
    "                filters,\n",
    "                num_bottleneck_units,\n",
    "                kernel_size,\n",
    "                dilation=dilation,\n",
    "                padding=\"same\",\n",
    "            ),\n",
    "            nn.BatchNorm1d(num_bottleneck_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(num_bottleneck_units, filters, kernel_size=1, padding=\"same\"),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.layer(x)\n",
    "\n",
    "class ResidualBlock2D(nn.Module):\n",
    "    def __init__(self, filters, filters1, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.BatchNorm2d(filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(filters, filters1, kernel_size, padding=\"same\"),\n",
    "            nn.BatchNorm2d(filters1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                filters1, filters, kernel_size, dilation=dilation, padding=\"same\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['resnet1d.0.weight', 'resnet1d.0.bias', 'resnet1d.1.layer.0.weight', 'resnet1d.1.layer.0.bias', 'resnet1d.1.layer.0.running_mean', 'resnet1d.1.layer.0.running_var', 'resnet1d.1.layer.0.num_batches_tracked', 'resnet1d.1.layer.2.weight', 'resnet1d.1.layer.2.bias', 'resnet1d.1.layer.3.weight', 'resnet1d.1.layer.3.bias', 'resnet1d.1.layer.3.running_mean', 'resnet1d.1.layer.3.running_var', 'resnet1d.1.layer.3.num_batches_tracked', 'resnet1d.1.layer.5.weight', 'resnet1d.1.layer.5.bias', 'resnet1d.2.layer.0.weight', 'resnet1d.2.layer.0.bias', 'resnet1d.2.layer.0.running_mean', 'resnet1d.2.layer.0.running_var', 'resnet1d.2.layer.0.num_batches_tracked', 'resnet1d.2.layer.2.weight', 'resnet1d.2.layer.2.bias', 'resnet1d.2.layer.3.weight', 'resnet1d.2.layer.3.bias', 'resnet1d.2.layer.3.running_mean', 'resnet1d.2.layer.3.running_var', 'resnet1d.2.layer.3.num_batches_tracked', 'resnet1d.2.layer.5.weight', 'resnet1d.2.layer.5.bias', 'convrank1.weight', 'convrank1.bias', 'convrank2.weight', 'convrank2.bias', 'resnet2d.0.weight', 'resnet2d.0.bias', 'resnet2d.1.layer.0.weight', 'resnet2d.1.layer.0.bias', 'resnet2d.1.layer.0.running_mean', 'resnet2d.1.layer.0.running_var', 'resnet2d.1.layer.0.num_batches_tracked', 'resnet2d.1.layer.2.weight', 'resnet2d.1.layer.2.bias', 'resnet2d.1.layer.3.weight', 'resnet2d.1.layer.3.bias', 'resnet2d.1.layer.3.running_mean', 'resnet2d.1.layer.3.running_var', 'resnet2d.1.layer.3.num_batches_tracked', 'resnet2d.1.layer.5.weight', 'resnet2d.1.layer.5.bias', 'resnet2d.2.layer.0.weight', 'resnet2d.2.layer.0.bias', 'resnet2d.2.layer.0.running_mean', 'resnet2d.2.layer.0.running_var', 'resnet2d.2.layer.0.num_batches_tracked', 'resnet2d.2.layer.2.weight', 'resnet2d.2.layer.2.bias', 'resnet2d.2.layer.3.weight', 'resnet2d.2.layer.3.bias', 'resnet2d.2.layer.3.running_mean', 'resnet2d.2.layer.3.running_var', 'resnet2d.2.layer.3.num_batches_tracked', 'resnet2d.2.layer.5.weight', 'resnet2d.2.layer.5.bias', 'conv2Dout.weight', 'conv2Dout.bias'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_keys = ['resnet1d.0.weight',\n",
    "                    'resnet1d.0.bias', \n",
    "                    'resnet1d.1.layer.0.weight', \n",
    "                    'resnet1d.1.layer.0.bias', \n",
    "                    'resnet1d.1.layer.0.running_mean', \n",
    "                    'resnet1d.1.layer.0.running_var', \n",
    "                    'resnet1d.1.layer.0.num_batches_tracked', \n",
    "                    'resnet1d.1.layer.2.weight', \n",
    "                    'resnet1d.1.layer.2.bias', \n",
    "                    'resnet1d.1.layer.3.weight', \n",
    "                    'resnet1d.1.layer.3.bias', \n",
    "                    'resnet1d.1.layer.3.running_mean', \n",
    "                    'resnet1d.1.layer.3.running_var', \n",
    "                    'resnet1d.1.layer.3.num_batches_tracked', \n",
    "                    'resnet1d.1.layer.5.weight', \n",
    "                    'resnet1d.1.layer.5.bias', \n",
    "                    'resnet1d.2.layer.0.weight', \n",
    "                    'resnet1d.2.layer.0.bias', \n",
    "                    'resnet1d.2.layer.0.running_mean', \n",
    "                    'resnet1d.2.layer.0.running_var', \n",
    "                    'resnet1d.2.layer.0.num_batches_tracked', \n",
    "                    'resnet1d.2.layer.2.weight', \n",
    "                    'resnet1d.2.layer.2.bias', \n",
    "                    'resnet1d.2.layer.3.weight', \n",
    "                    'resnet1d.2.layer.3.bias', \n",
    "                    'resnet1d.2.layer.3.running_mean', \n",
    "                    'resnet1d.2.layer.3.running_var', \n",
    "                    'resnet1d.2.layer.3.num_batches_tracked', \n",
    "                    'resnet1d.2.layer.5.weight', \n",
    "                    'resnet1d.2.layer.5.bias', \n",
    "                    'convrank1.weight', \n",
    "                    'convrank1.bias', \n",
    "                    'convrank2.weight', \n",
    "                    'convrank2.bias', \n",
    "                    'resnet2d.0.weight', \n",
    "                    'resnet2d.0.bias', \n",
    "                    'resnet2d.1.layer.0.weight', \n",
    "                    'resnet2d.1.layer.0.bias', \n",
    "                    'resnet2d.1.layer.0.running_mean', \n",
    "                    'resnet2d.1.layer.0.running_var', \n",
    "                    'resnet2d.1.layer.0.num_batches_tracked', \n",
    "                    'resnet2d.1.layer.2.weight', \n",
    "                    'resnet2d.1.layer.2.bias', \n",
    "                    'resnet2d.1.layer.3.weight', \n",
    "                    'resnet2d.1.layer.3.bias', \n",
    "                    'resnet2d.1.layer.3.running_mean', \n",
    "                    'resnet2d.1.layer.3.running_var', \n",
    "                    'resnet2d.1.layer.3.num_batches_tracked', \n",
    "                    'resnet2d.1.layer.5.weight', \n",
    "                    'resnet2d.1.layer.5.bias', \n",
    "                    'resnet2d.2.layer.0.weight', \n",
    "                    'resnet2d.2.layer.0.bias', \n",
    "                    'resnet2d.2.layer.0.running_mean', \n",
    "                    'resnet2d.2.layer.0.running_var', \n",
    "                    'resnet2d.2.layer.0.num_batches_tracked', \n",
    "                    'resnet2d.2.layer.2.weight', \n",
    "                    'resnet2d.2.layer.2.bias', \n",
    "                    'resnet2d.2.layer.3.weight', \n",
    "                    'resnet2d.2.layer.3.bias', \n",
    "                    'resnet2d.2.layer.3.running_mean', \n",
    "                    'resnet2d.2.layer.3.running_var', \n",
    "                    'resnet2d.2.layer.3.num_batches_tracked', \n",
    "                    'resnet2d.2.layer.5.weight', \n",
    "                    'resnet2d.2.layer.5.bias', \n",
    "                    'conv2Dout.weight', \n",
    "                    'conv2Dout.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase AblationNet heredando de SincFold\n",
    "class AblationNet(SincFold):\n",
    "    def __init__(self, original_net, layers_to_remove):\n",
    "        super(AblationNet, self).__init__(**original_net.config)  \n",
    "        self.load_state_dict(original_net.state_dict())        \n",
    "        self.layers_to_remove = layers_to_remove\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = batch[\"embedding\"].to(self.device)\n",
    "        batch_size = x.shape[0]\n",
    "        L = x.shape[2]\n",
    "        \n",
    "        \n",
    "        # y = self.resnet1d(x)\n",
    "        # ya = self.convrank1(y)\n",
    "        # ya = tr.transpose(ya, -1, -2)\n",
    "\n",
    "        ya = self.convrank1(x)\n",
    "        \n",
    "        ya = tr.transpose(ya, -1, -2)\n",
    "        yb = self.convrank2(x)\n",
    "\n",
    "        y = ya @ yb\n",
    "        yt = tr.transpose(y, -1, -2)\n",
    "        y = (y + yt) / 2\n",
    "\n",
    "        y0 = y.view(-1, L, L) \n",
    "\n",
    "        if self.interaction_prior != \"none\":\n",
    "            prob_mat = batch[\"interaction_prior\"].to(self.device)\n",
    "            x1 = tr.zeros([batch_size, 2, L, L]).to(self.device)\n",
    "            x1[:, 0, :, :] = y0\n",
    "            x1[:, 1, :, :] = prob_mat\n",
    "        else:\n",
    "            x1 = y0.unsqueeze(1)\n",
    "        \n",
    "        y = self.resnet2d(x1)\n",
    "\n",
    "        # if 'resnet2d' not in self.layers_to_remove:\n",
    "        #     y = self.resnet2d(x1)\n",
    "        # else:\n",
    "        #     y = x1\n",
    "\n",
    "        # output\n",
    "        y = self.conv2Dout(tr.relu(y)).squeeze(1)\n",
    "        if batch[\"canonical_mask\"] is not None:\n",
    "            y = y.multiply(batch[\"canonical_mask\"].to(self.device))\n",
    "        yt = tr.transpose(y, -1, -2)\n",
    "        y = (y + yt) / 2\n",
    "\n",
    "        return y, y0 \n",
    "\n",
    "\n",
    "layers_to_remove = ['resnet2d']  \n",
    "ablated_net = AblationNet(net, layers_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AblationNet(\n",
       "  (resnet1d): Sequential(\n",
       "    (0): Conv1d(4, 32, kernel_size=(3,), stride=(1,), padding=same)\n",
       "    (1): ResidualLayer1D(\n",
       "      (layer): Sequential(\n",
       "        (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=same, dilation=(3,))\n",
       "        (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Conv1d(16, 32, kernel_size=(1,), stride=(1,), padding=same)\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualLayer1D(\n",
       "      (layer): Sequential(\n",
       "        (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=same, dilation=(3,))\n",
       "        (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Conv1d(16, 32, kernel_size=(1,), stride=(1,), padding=same)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (convrank1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (convrank2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (resnet2d): Sequential(\n",
       "    (0): Conv2d(2, 256, kernel_size=(7, 7), stride=(1, 1), padding=same)\n",
       "    (1): ResidualBlock2D(\n",
       "      (layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, dilation=(3, 3))\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock2D(\n",
       "      (layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU()\n",
       "        (5): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, dilation=(3, 3))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv2Dout): Conv2d(256, 1, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablated_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test of ../data/ArchiveII_sample.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 32, 3], expected input[4, 4, 356] to have 32 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart test of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)        \n\u001b[0;32m----> 3\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mablated_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(test_metrics\u001b[38;5;241m.\u001b[39mkeys())]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_metrics[k]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(test_metrics\u001b[38;5;241m.\u001b[39mkeys())])\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/sincfold/lib/python3.9/site-packages/sincfold/model.py:277\u001b[0m, in \u001b[0;36mSincFold.test\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    273\u001b[0m batch\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontact\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    274\u001b[0m lengths \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 277\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_func(y_pred, y)\n\u001b[1;32m    279\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 18\u001b[0m, in \u001b[0;36mAblationNet.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m L \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# y = self.resnet1d(x)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# ya = self.convrank1(y)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ya = tr.transpose(ya, -1, -2)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m ya \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvrank1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m ya \u001b[38;5;241m=\u001b[39m tr\u001b[38;5;241m.\u001b[39mtranspose(ya, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     21\u001b[0m yb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvrank2(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 32, 3], expected input[4, 4, 356] to have 32 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    print(f\"Start test of {test_file}\")        \n",
    "test_metrics = ablated_net.test(test_loader)\n",
    "summary = \",\".join([k for k in sorted(test_metrics.keys())]) + \"\\n\" + \",\".join([f\"{test_metrics[k]:.3f}\" for k in sorted(test_metrics.keys())])+ \"\\n\" \n",
    "if output_file is not None:\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(summary)\n",
    "if verbose:\n",
    "    print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sincfold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
